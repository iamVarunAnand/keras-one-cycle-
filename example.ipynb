{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.callbacks import Callback, LambdaCallback\n",
    "from keras.datasets import cifar10, mnist\n",
    "from keras.applications import MobileNet, imagenet_utils\n",
    "from keras.optimizers import SGD, Adam\n",
    "\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.core import Activation\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config = config)\n",
    "set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneCycleScheduler(Callback):\n",
    "    def __init__(self, epochs, max_lr, steps_per_epoch, moms = (0.95, 0.85), div_factor = 25, start_pct = 0.3):\n",
    "        # initialize the instance variables\n",
    "        self.max_lr = max_lr\n",
    "        self.moms = moms\n",
    "        self.div_factor = div_factor\n",
    "        self.st1_epochs = int(np.floor(epochs * start_pct))\n",
    "        self.st2_epochs = epochs - self.st1_epochs\n",
    "        self.st1_steps = self.st1_epochs * steps_per_epoch\n",
    "        self.st2_steps = self.st2_epochs * steps_per_epoch\n",
    "        self.history = {\"lrs\" : [], \"moms\" : []}\n",
    "    \n",
    "    def __annealing_cos(self, start, end, pct):\n",
    "        \"Cosine anneal from `start` to `end` as pct goes from 0.0 to 1.0.\"\n",
    "\n",
    "        cos_out = np.cos(np.pi * pct) + 1    \n",
    "        return end + (start - end) / 2 * cos_out\n",
    "    \n",
    "    def on_train_begin(self, logs = None):\n",
    "        # initialize the necessary variables\n",
    "        self.steps_so_far = 0         \n",
    "    \n",
    "    def on_batch_begin(self, batch, logs = None):\n",
    "        # increment the step count         \n",
    "        self.steps_so_far += 1\n",
    "        \n",
    "        # check to determine the training phase\n",
    "        if self.steps_so_far <= self.st1_steps:\n",
    "            # calculate the new learning rate             \n",
    "            new_lr = self.__annealing_cos(self.max_lr / self.div_factor, \n",
    "                                          self.max_lr, \n",
    "                                          self.steps_so_far / self.st1_steps)\n",
    "            \n",
    "            # calculate the new momentum\n",
    "            new_mom = self.__annealing_cos(self.moms[0],\n",
    "                                          self.moms[1],\n",
    "                                          self.steps_so_far / self.st1_steps)\n",
    "            \n",
    "            # set the new learning rate and momentum\n",
    "            K.set_value(self.model.optimizer.lr, new_lr)\n",
    "            K.set_value(self.model.optimizer.momentum, new_mom)\n",
    "\n",
    "        else:\n",
    "            # calculate the new learning rate             \n",
    "            new_lr = self.__annealing_cos(self.max_lr, \n",
    "                                          self.max_lr / self.div_factor, \n",
    "                                          (self.steps_so_far - self.st1_steps) / self.st2_steps)\n",
    "            \n",
    "            # calculate the new momentum\n",
    "            new_mom = self.__annealing_cos(self.moms[1],\n",
    "                                           self.moms[0],\n",
    "                                           (self.steps_so_far - self.st1_steps) / self.st2_steps)\n",
    "            \n",
    "            # set the new learning rate and momentum\n",
    "            K.set_value(self.model.optimizer.lr, new_lr)\n",
    "            K.set_value(self.model.optimizer.momentum, new_mom)\n",
    "            \n",
    "        # update the history attribute\n",
    "        self.history[\"lrs\"].append(new_lr)\n",
    "        self.history[\"moms\"].append(new_mom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# scale the images into [0, 1]\n",
    "x_train = x_train.astype(np.float32) * (255.0 / x_train.max())\n",
    "x_test = x_test.astype(np.float32) * (255.0 / x_test.max())\n",
    "\n",
    "# preprocess the images\n",
    "x_train = imagenet_utils.preprocess_input(x_train, mode = \"tf\")\n",
    "x_test = imagenet_utils.preprocess_input(x_test, mode = \"tf\")\n",
    "\n",
    "# convert the labels from integers into vectors\n",
    "lb = LabelBinarizer()\n",
    "y_train = lb.fit_transform(y_train)\n",
    "y_test = lb.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MobileNetClassifier:\n",
    "    @staticmethod\n",
    "    def build(base_model, classes):\n",
    "        #  GlobalAveragePooling\n",
    "        x = GlobalAveragePooling2D()(base_model.output)\n",
    "        \n",
    "        # FC => RELU block\n",
    "        x = Dense(256, kernel_initializer = \"he_normal\")(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        \n",
    "        # Softmax classifier\n",
    "        x = Dense(classes, kernel_initializer = \"he_normal\")(x)\n",
    "        x = Activation(\"softmax\")(x)\n",
    "        \n",
    "        # return the constructed model architecture    \n",
    "        return Model(inputs = base_model.input, outputs = x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the base model\n",
    "base_model = MobileNet(include_top = False, weights = \"imagenet\", input_shape = (32, 32, 3))\n",
    "\n",
    "# # freeze the base model\n",
    "# for layer in base_model.layers:\n",
    "#     layer.trainable = False\n",
    "\n",
    "# construct the classifier\n",
    "model = MobileNetClassifier.build(base_model, 10)\n",
    "\n",
    "# compile the model\n",
    "opt = SGD(lr = 0.01, momentum = 0.9, nesterov = True)\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = opt, metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the training parameters\n",
    "epochs = 5\n",
    "bs = 128\n",
    "steps_per_epoch = np.ceil(x_train.shape[0] / bs)\n",
    "max_lr = 0.01\n",
    "\n",
    "# initialize the one cycle scheduler\n",
    "ocs = OneCycleScheduler(epochs, max_lr, steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "model.fit(x_train, y_train, validation_data = (x_test, y_test), \n",
    "          epochs = epochs, batch_size = bs,\n",
    "          callbacks = [ocs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize = (8, 3))\n",
    "ax[0].plot(ocs.history[\"lrs\"])\n",
    "ax[0].set_title(\"Learning Rate\")\n",
    "ax[0].set_xlabel(\"Iterations\")\n",
    "ax[1].plot(ocs.history[\"moms\"])\n",
    "ax[1].set_title(\"Momentum\")\n",
    "ax[1].set_xlabel(\"Iterations\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python36964bit0a6a3af0c6c942d9aaac98da71ec5a43"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}